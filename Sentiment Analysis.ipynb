{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ee73a5",
   "metadata": {},
   "source": [
    "# Sentiment basé sur les reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c819a",
   "metadata": {},
   "source": [
    "J'ai testé différent Dataset avec différents modèle de text mining pour prédire les sentiments à partir des reviews.\n",
    "Une première approche en utilisant le Dataset twitter.\n",
    "Une deuxième approche en utilisant nos propres jeux de données Trustpilot\n",
    "Le modèle qui fonctionne le mieux pour le moment est le modèle bag CountVectorizer. Le modèle prédit assez bien pour les avis positifs et un peu moins bien pour les avis négatifs et neutre. \n",
    "Des solutions pour améliorer le modèle:\n",
    "* Ajout de données pour l'entrainement\n",
    "* Utiliser un modèle de text Mining Pré-entrainer sur un gros volume de données tel que Vader\n",
    "* Utiliser d'autre Dataset ou d'autres modèles de text mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465ec04-2c77-4dc2-938a-59ff90d885ef",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c926b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "if nltk.download('punkt') == True:\n",
    "    pass\n",
    "else:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952744d",
   "metadata": {},
   "source": [
    "# Nettoyage et traitement jeu de données"
   ]
  },
  {
   "cell_type": "raw",
   "id": "526e8aad",
   "metadata": {},
   "source": [
    "Fonction qui permet de récuperer les tokens dans la reviews. On filtre pour garder les tokens seulement avec une longueur supérieur ou égale à 4 pour garder une cohérence dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03586430",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"[a-zA-Z0-9]{4,}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ae905b9",
   "metadata": {},
   "source": [
    "Fonction qui va permettre d'enlever les stopwords pour chaques reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d2cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([\".\",\",\",\"?\",\"@\"])\n",
    "\n",
    "def stop_words_filtering(l):\n",
    "    for element in l:\n",
    "        if element in stop_words:\n",
    "            l.remove(element)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d47cc297",
   "metadata": {},
   "source": [
    "Fonction de lemmatisation qui permet de réduire le mot dans sa forme canonique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6e89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatisation(mots):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    result = []\n",
    "    for element in mots:\n",
    "        radical = wordnet_lemmatizer.lemmatize(element, pos='v')\n",
    "        if (radical not in result):\n",
    "            result.append(radical)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff1cd01e",
   "metadata": {},
   "source": [
    "Fonction de stemmer pour réduire le mot à sa racine. on a décidé de ne pas l'utiliser car la lemmatisation est plus performante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feac862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(mots) :\n",
    "    stemmer = PorterStemmer()\n",
    "    sortie = []\n",
    "    for string in mots :\n",
    "        radical = stemmer.stem(string)\n",
    "        if (radical not in sortie) : sortie.append(radical)\n",
    "    return sortie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a117bb0",
   "metadata": {},
   "source": [
    "# Twitter Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73643240",
   "metadata": {},
   "source": [
    "Source https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2e154-6fcd-4282-a813-0021cc928ab6",
   "metadata": {},
   "source": [
    "L'objectif est de créer un modèle capable de prédire si un texte est positif neutre ou négatif. Pour cela on va prendre un jeu de donnée contenant des reviews avec leur label. Après cet entrainement, on va tester le modèle avec nos propres données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfb8673-58a3-4c6d-b613-1d9171ce03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_twitter_data = f\"{os.getcwd()}/train_data/Twitter_Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db2e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter = pd.read_csv(path_twitter_data, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7051bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter[\"category\"] = data_twitter[\"category\"].replace(to_replace = -1.0, value = \"negatif\")\n",
    "data_twitter[\"category\"] = data_twitter[\"category\"].replace(to_replace = 1.0, value = \"positif\")\n",
    "data_twitter[\"category\"] = data_twitter[\"category\"].replace(to_replace = 0.0, value = \"neutre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149828b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter = data_twitter.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c2ebf8c",
   "metadata": {},
   "source": [
    "On voit ici que les valeurs ne sont pas équilibré, pour éviter l'overfitting sur une valeur on va équilibré nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd655f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "positif    72249\n",
       "neutre     55211\n",
       "negatif    35509\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_twitter[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc89d4c5",
   "metadata": {},
   "source": [
    "On équilibre nos données en faisant du sous_échantillonnage en prenant la valeur \"negatif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a97e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter_positif = data_twitter[data_twitter['category'] == 'positif'].sample(n=35509, random_state=42)\n",
    "data_twitter_neutre = data_twitter[data_twitter['category'] == 'neutre'].sample(n=35509, random_state=42)\n",
    "data_twitter_negatif = data_twitter[data_twitter['category'] == 'negatif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6f429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twitter = pd.concat([data_twitter_positif, data_twitter_negatif,data_twitter_neutre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708a3306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "positif    35509\n",
       "negatif    35509\n",
       "neutre     35509\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_twitter[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee76b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a en tout 106527 lignes pour notre modèle\n"
     ]
    }
   ],
   "source": [
    "print(f\"On a en tout {len(data_twitter)} lignes pour notre modèle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc018448-5ac7-40ff-b909-c2e9530fdd77",
   "metadata": {},
   "source": [
    "# Algo BAG avec CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ae08c-ad4d-414f-90ec-dd81b188d71a",
   "metadata": {},
   "source": [
    "On va prendre importer nos données d'entrainements et on va ensuite diviser en jeu d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966b170a-a005-4cc0-acbf-582b91ae7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"modelCV_twitter.pkl\"\n",
    "if os.path.exists(f\"{os.getcwd()}/model/{model_name}\"):\n",
    "\n",
    "    vectorizer, model_clf_CV_twitter = joblib.load(f\"{os.getcwd()}/model/{model_name}\")\n",
    "    X_test, y_test = joblib.load(f\"{os.getcwd()}/model/test_data_twitter_CV.pkl\")\n",
    "\n",
    "else:\n",
    "    X = data_twitter[\"clean_text\"]\n",
    "    y = data_twitter[\"category\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 30)\n",
    "\n",
    "    X_train = X_train.str.lower().apply(tokenizer.tokenize)\n",
    "    X_test = X_test.str.lower().apply(tokenizer.tokenize)\n",
    "    \n",
    "    X_train = X_train.apply(stop_words_filtering)\n",
    "    X_test = X_test.apply(stop_words_filtering)\n",
    "    \n",
    "    X_train = X_train.apply(lemmatisation)\n",
    "    X_test = X_test.apply(lemmatisation)\n",
    "    \n",
    "    X_train = X_train.apply(str)\n",
    "    X_test = X_test.apply(str)\n",
    "\n",
    "    #application du CountVectorizer sur nos jeux d'entrainements et de tests\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    model_clf_CV_twitter = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42).fit(X_train, y_train)\n",
    "    joblib.dump((vectorizer,model_clf_CV_twitter), f\"{os.getcwd()}/model/{model_name}\")\n",
    "    joblib.dump((X_test, y_test), f\"{os.getcwd()}/model/test_data_twitter_CV.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83677e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_clf_CV_twitter.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2b353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.85      0.72      0.78      7021\n",
      "      neutre       0.70      0.95      0.81      7200\n",
      "     positif       0.87      0.69      0.77      7085\n",
      "\n",
      "    accuracy                           0.79     21306\n",
      "   macro avg       0.81      0.79      0.79     21306\n",
      "weighted avg       0.81      0.79      0.79     21306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d4d6f4-7e90-4ded-8d35-80de9e1a54ca",
   "metadata": {},
   "source": [
    "Cette fonction prends en entrée un pandas Serie de texte et le modèle et renvoie en sortie une liste avec nos prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfd8dc4-23ef-4b1d-87e7-18a3d9872327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment_cv(reviews,model_CV):\n",
    "    result = []\n",
    "    reviews = reviews.str.lower().apply(tokenizer.tokenize)\n",
    "    reviews = reviews.apply(stop_words_filtering)\n",
    "    reviews = reviews.apply(lemmatisation)\n",
    "    reviews = reviews.apply(str)\n",
    "    for text in reviews:\n",
    "        new_text_vectorized = vectorizer.transform([text])\n",
    "\n",
    "        prediction = model_CV.predict(new_text_vectorized)\n",
    "        result.append(prediction[0])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc6724-ba69-44ea-bc8e-d89be5a327d2",
   "metadata": {},
   "source": [
    "# Algo BAG avec TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222003c-6f6c-44ef-a600-2b6abc566a62",
   "metadata": {},
   "source": [
    "La même chose avec tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a52ccf02-13e8-4985-8e4f-aa91a67564c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"modeltfidf_twitter.pkl\"\n",
    "if os.path.exists(f\"{os.getcwd()}/model/{model_name}\"):\n",
    "\n",
    "    vec_tfidf, model_CLF_tfidf_twitter = joblib.load(f\"{os.getcwd()}/model/{model_name}\")\n",
    "    X_test_tfidf, y_test_tfidf = joblib.load(f\"{os.getcwd()}/model/test_data_twitter_tfidf.pkl\")\n",
    "\n",
    "else:\n",
    "    X = data_twitter[\"clean_text\"]\n",
    "    y = data_twitter[\"category\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 30)\n",
    "\n",
    "    X_train = X_train.str.lower().apply(tokenizer.tokenize)\n",
    "    X_test = X_test.str.lower().apply(tokenizer.tokenize)\n",
    "    \n",
    "    X_train = X_train.apply(stop_words_filtering)\n",
    "    X_test = X_test.apply(stop_words_filtering)\n",
    "    \n",
    "    X_train = X_train.apply(lemmatisation)\n",
    "    X_test = X_test.apply(lemmatisation)\n",
    "    \n",
    "    X_train = X_train.apply(str)\n",
    "    X_test = X_test.apply(str)\n",
    "\n",
    "    #application du TfidfVectorizer sur nos jeux d'entrainements et de tests\n",
    "    vec_tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = vec_tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = vec_tfidf.transform(X_test)\n",
    "\n",
    "    model_CLF_tfidf_twitter = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42).fit(X_train_tfidf, y_train)\n",
    "    joblib.dump((vec_tfidf, model_CLF_tfidf_twitter), f\"{os.getcwd()}/model/{model_name}\")\n",
    "    joblib.dump((X_test_tfidf, y_test), f\"{os.getcwd()}/model/test_data_twitter_tfidf.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "215ac92c-e312-4114-8d74-5851a1ef2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = model_CLF_tfidf_twitter.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c103695-6fd3-460f-aa01-948640f0e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.83      0.71      0.76      7021\n",
      "      neutre       0.70      0.95      0.80      7200\n",
      "     positif       0.87      0.67      0.75      7085\n",
      "\n",
      "    accuracy                           0.78     21306\n",
      "   macro avg       0.80      0.78      0.77     21306\n",
      "weighted avg       0.80      0.78      0.77     21306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fae2ed38-be6e-4782-b26d-7c641a6938bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment_tfidf(reviews,model_tfidf):\n",
    "    result = []\n",
    "    reviews = reviews.str.lower().apply(tokenizer.tokenize)\n",
    "    reviews = reviews.apply(stop_words_filtering)\n",
    "    reviews = reviews.apply(lemmatisation)\n",
    "    reviews = reviews.apply(str)\n",
    "    for text in reviews:\n",
    "\n",
    "        new_text_vectorized = vec_tfidf.transform([text])\n",
    "\n",
    "        prediction = model_tfidf.predict(new_text_vectorized)\n",
    "        result.append(prediction[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f709c6-d115-422a-98e8-678ce8a8160a",
   "metadata": {},
   "source": [
    "# Sentiments Analysis avec Trustpilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb00487-bf0c-41cc-ada2-9b5f5633d4e1",
   "metadata": {},
   "source": [
    "On va se servir de nos propres jeux de données truspilot dans ce cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff03658-d326-4973-ae34-03ca7d77d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trustpilot_data = f\"{os.getcwd()}/train_data/debt_relief_service_raw_reviews_COMPLETE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9736aaa2-141c-4ab6-be6f-bd411bc05c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_trustpilot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d905cf9-2c7d-45ed-81a0-eacc1a5325de",
   "metadata": {},
   "source": [
    "Ici nous avons entrainé notre modèle avec nos propres données que l'on a scrappé sur truspilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490930c2-5223-48c6-9f3b-74e0f2ef8235",
   "metadata": {},
   "source": [
    "Un petit aperçu de nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40377b4b-6e83-468b-99ec-4c32f09a7c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>firm_name</th>\n",
       "      <th>review_url</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>note</th>\n",
       "      <th>reponse</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_url</th>\n",
       "      <th>author_localisation</th>\n",
       "      <th>experience_date</th>\n",
       "      <th>extract_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646cba0dc423446286686604</td>\n",
       "      <td>Alvaro made my experience very…</td>\n",
       "      <td>Alvaro made my experience very satisfactory! I...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Keontra Reid</td>\n",
       "      <td>/users/646cba0ba8905b00124cdbfb</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646cad6cc423446286685c19</td>\n",
       "      <td>Great company to work with they really…</td>\n",
       "      <td>Great company to work with they really underst...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Ismael Luciano</td>\n",
       "      <td>/users/646cad6b05330f0014134602</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c8127706f837cb1eff2f6</td>\n",
       "      <td>HELPFUL..</td>\n",
       "      <td>HELPFUL... HONEST...TRUTHUL!!!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Tony RODRIGUEZ</td>\n",
       "      <td>/users/646c8126a8905b00124cad7c</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c6c27706f837cb1efe4ad</td>\n",
       "      <td>Making it very easy to understand and…</td>\n",
       "      <td>Making it very easy to understand and answerin...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Melinda Hall</td>\n",
       "      <td>/users/646c6c254be4ac0013350e3c</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c4e46706f837cb1efd615</td>\n",
       "      <td>Leif was awesome</td>\n",
       "      <td>Leif was awesome. Hes so friendly, easy to tal...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>SDS</td>\n",
       "      <td>/users/646c4e454be4ac001334fb5f</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        firm_id  firm_name                         review_url  \\\n",
       "0           0  turbodebt.com  TurboDebt  /reviews/646cba0dc423446286686604   \n",
       "1           1  turbodebt.com  TurboDebt  /reviews/646cad6cc423446286685c19   \n",
       "2           2  turbodebt.com  TurboDebt  /reviews/646c8127706f837cb1eff2f6   \n",
       "3           3  turbodebt.com  TurboDebt  /reviews/646c6c27706f837cb1efe4ad   \n",
       "4           4  turbodebt.com  TurboDebt  /reviews/646c4e46706f837cb1efd615   \n",
       "\n",
       "                              review_title  \\\n",
       "0          Alvaro made my experience very…   \n",
       "1  Great company to work with they really…   \n",
       "2                                HELPFUL..   \n",
       "3   Making it very easy to understand and…   \n",
       "4                         Leif was awesome   \n",
       "\n",
       "                                         review_text review_date  note  \\\n",
       "0  Alvaro made my experience very satisfactory! I...  2023-05-23   5.0   \n",
       "1  Great company to work with they really underst...  2023-05-23   5.0   \n",
       "2     HELPFUL... HONEST...TRUTHUL!!!!!!!!!!!!!!!!!!!  2023-05-23   5.0   \n",
       "3  Making it very easy to understand and answerin...  2023-05-23   5.0   \n",
       "4  Leif was awesome. Hes so friendly, easy to tal...  2023-05-23   5.0   \n",
       "\n",
       "   reponse     author_name                       author_url  \\\n",
       "0     True    Keontra Reid  /users/646cba0ba8905b00124cdbfb   \n",
       "1     True  Ismael Luciano  /users/646cad6b05330f0014134602   \n",
       "2     True  Tony RODRIGUEZ  /users/646c8126a8905b00124cad7c   \n",
       "3     True    Melinda Hall  /users/646c6c254be4ac0013350e3c   \n",
       "4     True             SDS  /users/646c4e454be4ac001334fb5f   \n",
       "\n",
       "  author_localisation experience_date extract_date  \n",
       "0                  US      2023-05-22   2024-08-23  \n",
       "1                  US      2023-05-22   2024-08-23  \n",
       "2                  US      2023-05-22   2024-08-23  \n",
       "3                  US      2023-05-22   2024-08-23  \n",
       "4                  US      2023-05-22   2024-08-23  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddbb7232-fb9d-4edf-980f-bfe01e5f06fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons en tout 214824 lignes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nous avons en tout {len(df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec7239b-6c8a-49f0-a772-7581086bef38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après avoir supprimé les NaN nous avons 188262 lignes\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"Après avoir supprimé les NaN nous avons {len(df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2358717-5922-4970-a114-a1c88744bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiments\"] = df[\"note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8407e99b-e243-4beb-becb-00fefb8c942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiments\"] = df[\"sentiments\"].replace(to_replace = [2.0,1.0], value = \"negatif\")\n",
    "df[\"sentiments\"] = df[\"sentiments\"].replace(to_replace = [4.0,5.0], value = \"positif\")\n",
    "df[\"sentiments\"] = df[\"sentiments\"].replace(to_replace = [3.0], value = \"neutre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "671eea05-2de4-4f65-9246-f9fe1659f1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "positif    176578\n",
       "negatif      7364\n",
       "neutre       4320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiments\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd180a2e-a4a7-4543-bacb-3b63dd528643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positif = df[df['sentiments'] == 'positif'].sample(n=8000, random_state=42)\n",
    "df_negatif = df[df['sentiments'] == 'negatif']\n",
    "df_neutre = df[df['sentiments'] == 'neutre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e761a37-c3b5-4f4c-8dd3-c80432089f51",
   "metadata": {},
   "source": [
    "Notre jeux de données est déjà plus équilibré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c290d7b-741c-4536-9632-70174d843046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "positif    176578\n",
       "negatif      7364\n",
       "neutre       4320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiments\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7427ce05-ddc7-49b0-9b69-d3dbe406128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_positif, df_negatif, df_neutre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49907b9f-bb20-4dac-a179-8cdce1c5f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"modelCV_trustpilot.pkl\"\n",
    "if os.path.exists(f\"{os.getcwd()}/model/{model_name}\"):\n",
    "\n",
    "    vectorizer, model_clf_CV_trustpilot = joblib.load(f\"{os.getcwd()}/model/{model_name}\")\n",
    "    X_test, y_test = joblib.load(f\"{os.getcwd()}/model/test_data_trustpilot_CV.pkl\")\n",
    "\n",
    "else:\n",
    "    X = df[\"review_text\"]\n",
    "    y = df[\"sentiments\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 30)\n",
    "\n",
    "    X_train = X_train.str.lower().apply(tokenizer.tokenize)\n",
    "    X_test = X_test.str.lower().apply(tokenizer.tokenize)\n",
    "    \n",
    "    X_train = X_train.apply(stop_words_filtering)\n",
    "    X_test = X_test.apply(stop_words_filtering)\n",
    "        \n",
    "    X_train = X_train.apply(lemmatisation)\n",
    "    X_test = X_test.apply(lemmatisation)\n",
    "        \n",
    "    X_train = X_train.apply(str)\n",
    "    X_test = X_test.apply(str)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    model_clf_CV_trustpilot = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42).fit(X_train, y_train)\n",
    "    joblib.dump((vectorizer,model_clf_CV_trustpilot), f\"{os.getcwd()}/model/{model_name}\")\n",
    "    joblib.dump((X_test, y_test), f\"{os.getcwd()}/model/test_data_trustpilot_CV.pkl\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "579e86f2-1a1e-42ac-8a35-e95c3f495a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_clf_CV_trustpilot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50971a52-ee59-4f51-8e02-92186a6a2e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.74      0.77      0.76      1462\n",
      "      neutre       0.52      0.39      0.45       861\n",
      "     positif       0.80      0.89      0.84      1614\n",
      "\n",
      "    accuracy                           0.74      3937\n",
      "   macro avg       0.69      0.68      0.68      3937\n",
      "weighted avg       0.72      0.74      0.73      3937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbce5f-07c0-40c8-bfbe-a1c7de9feddf",
   "metadata": {},
   "source": [
    "# Test du modèle avec nos jeux de données sur mongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c35820-bd90-4254-9450-0206e66230b2",
   "metadata": {},
   "source": [
    "Une fois qu'on a notre modèle on l'utiliser sur nos données scrappés qui se trouvent dans la base mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afefc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\n",
    "    host = \"127.0.0.1\",\n",
    "    port = 27017,\n",
    "    username = \"datascientest\",\n",
    "    password = \"dst123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0744b65-7846-456e-b251-2c8a583f7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0,\n",
      " '_id': ObjectId('66d1e81ee0bf53857f7ffc70'),\n",
      " 'author_localisation': 'US',\n",
      " 'author_name': 'Keontra Reid',\n",
      " 'author_url': '/users/646cba0ba8905b00124cdbfb',\n",
      " 'experience_date': '2023-05-22',\n",
      " 'extract_date': '2024-08-23',\n",
      " 'firm_id': 'turbodebt.com',\n",
      " 'firm_name': 'TurboDebt',\n",
      " 'note': 5.0,\n",
      " 'reponse': True,\n",
      " 'review_date': '2023-05-23',\n",
      " 'review_text': 'Alvaro made my experience very satisfactory! I felt like I '\n",
      "                'could breathe again after speaking with him.',\n",
      " 'review_title': 'Alvaro made my experience very…',\n",
      " 'review_url': '/reviews/646cba0dc423446286686604'}\n"
     ]
    }
   ],
   "source": [
    "pprint(client[\"test\"][\"reviews\"].find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9954bd75-7528-46c1-b4e4-755b7c9f918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(client.list_database_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6cc95-97b4-48c0-a34f-374d7d51693d",
   "metadata": {},
   "source": [
    "Liste des colonnes de notre jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7bb1122-6855-40ae-b91b-239843fabe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'Unnamed: 0', 'firm_id', 'firm_name', 'review_url', 'review_title', 'review_text', 'review_date', 'note', 'reponse', 'author_name', 'author_url', 'author_localisation', 'experience_date', 'extract_date'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client[\"test\"][\"reviews\"].find_one().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10029b14-171c-438f-884b-002b9136bf3e",
   "metadata": {},
   "source": [
    "Ajout dans une liste de toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0a2e8ac-d58c-4a75-a068-83e89446f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for element in client[\"test\"][\"reviews\"].find({},{ \"_id\":0 }):\n",
    "    full_data.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031ce94-3d00-4929-8c6b-0e37f924ca84",
   "metadata": {},
   "source": [
    "Création du DataFrame contenant toutes nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef3016ae-3e0f-4027-a27f-c998fda79a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55252ad-eb92-4e41-81b7-ad1d792d93cc",
   "metadata": {},
   "source": [
    "On supprime les lignes où dans la colonne review_text on voit des valeurs NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4872903-3289-4a5f-b49a-f82e64654a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['review_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390ad4c-7957-4b1d-9836-916b21720297",
   "metadata": {},
   "source": [
    "On utilise CV pour nos prédiction car c'est celui avec lequel on obtient nos meilleurs résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "836e2f9d-be14-4ba5-afe3-e3090a974b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment_cv(reviews,model_CV):\n",
    "    result = []\n",
    "    reviews = reviews.str.lower().apply(tokenizer.tokenize)\n",
    "    reviews = reviews.apply(stop_words_filtering)\n",
    "    reviews = reviews.apply(lemmatisation)\n",
    "    reviews = reviews.apply(str)\n",
    "    for text in reviews:\n",
    "        new_text_vectorized = vectorizer.transform([text])\n",
    "\n",
    "        prediction =  model_clf_CV_trustpilot.predict(new_text_vectorized)\n",
    "        result.append(prediction[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23b31d8a-714d-4f66-9539-d68a58255e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiments\"] = extract_sentiment_cv(data[\"review_text\"], model_clf_CV_trustpilot)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab533e26-83fd-4590-8584-eedb6710c3e3",
   "metadata": {},
   "source": [
    "Voici notre dataset final qu'on va ensuite intégrer dans SQL et ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92ebaf01-d461-453c-b89e-9801d753eb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>firm_id</th>\n",
       "      <th>firm_name</th>\n",
       "      <th>review_url</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>note</th>\n",
       "      <th>reponse</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_url</th>\n",
       "      <th>author_localisation</th>\n",
       "      <th>experience_date</th>\n",
       "      <th>extract_date</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646cba0dc423446286686604</td>\n",
       "      <td>Alvaro made my experience very…</td>\n",
       "      <td>Alvaro made my experience very satisfactory! I...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Keontra Reid</td>\n",
       "      <td>/users/646cba0ba8905b00124cdbfb</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646cad6cc423446286685c19</td>\n",
       "      <td>Great company to work with they really…</td>\n",
       "      <td>Great company to work with they really underst...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Ismael Luciano</td>\n",
       "      <td>/users/646cad6b05330f0014134602</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c8127706f837cb1eff2f6</td>\n",
       "      <td>HELPFUL..</td>\n",
       "      <td>HELPFUL... HONEST...TRUTHUL!!!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Tony RODRIGUEZ</td>\n",
       "      <td>/users/646c8126a8905b00124cad7c</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c6c27706f837cb1efe4ad</td>\n",
       "      <td>Making it very easy to understand and…</td>\n",
       "      <td>Making it very easy to understand and answerin...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Melinda Hall</td>\n",
       "      <td>/users/646c6c254be4ac0013350e3c</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>turbodebt.com</td>\n",
       "      <td>TurboDebt</td>\n",
       "      <td>/reviews/646c4e46706f837cb1efd615</td>\n",
       "      <td>Leif was awesome</td>\n",
       "      <td>Leif was awesome. Hes so friendly, easy to tal...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>SDS</td>\n",
       "      <td>/users/646c4e454be4ac001334fb5f</td>\n",
       "      <td>US</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        firm_id  firm_name                         review_url  \\\n",
       "0           0  turbodebt.com  TurboDebt  /reviews/646cba0dc423446286686604   \n",
       "1           1  turbodebt.com  TurboDebt  /reviews/646cad6cc423446286685c19   \n",
       "2           2  turbodebt.com  TurboDebt  /reviews/646c8127706f837cb1eff2f6   \n",
       "3           3  turbodebt.com  TurboDebt  /reviews/646c6c27706f837cb1efe4ad   \n",
       "4           4  turbodebt.com  TurboDebt  /reviews/646c4e46706f837cb1efd615   \n",
       "\n",
       "                              review_title  \\\n",
       "0          Alvaro made my experience very…   \n",
       "1  Great company to work with they really…   \n",
       "2                                HELPFUL..   \n",
       "3   Making it very easy to understand and…   \n",
       "4                         Leif was awesome   \n",
       "\n",
       "                                         review_text review_date  note  \\\n",
       "0  Alvaro made my experience very satisfactory! I...  2023-05-23   5.0   \n",
       "1  Great company to work with they really underst...  2023-05-23   5.0   \n",
       "2     HELPFUL... HONEST...TRUTHUL!!!!!!!!!!!!!!!!!!!  2023-05-23   5.0   \n",
       "3  Making it very easy to understand and answerin...  2023-05-23   5.0   \n",
       "4  Leif was awesome. Hes so friendly, easy to tal...  2023-05-23   5.0   \n",
       "\n",
       "   reponse     author_name                       author_url  \\\n",
       "0     True    Keontra Reid  /users/646cba0ba8905b00124cdbfb   \n",
       "1     True  Ismael Luciano  /users/646cad6b05330f0014134602   \n",
       "2     True  Tony RODRIGUEZ  /users/646c8126a8905b00124cad7c   \n",
       "3     True    Melinda Hall  /users/646c6c254be4ac0013350e3c   \n",
       "4     True             SDS  /users/646c4e454be4ac001334fb5f   \n",
       "\n",
       "  author_localisation experience_date extract_date sentiments  \n",
       "0                  US      2023-05-22   2024-08-23    positif  \n",
       "1                  US      2023-05-22   2024-08-23    positif  \n",
       "2                  US      2023-05-22   2024-08-23    positif  \n",
       "3                  US      2023-05-22   2024-08-23    positif  \n",
       "4                  US      2023-05-22   2024-08-23    positif  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f40f7f86-8bc6-4d01-915b-e1603362fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_final.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdea286a-d5fd-40f5-917e-87411d75dbf1",
   "metadata": {},
   "source": [
    "Suite..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
